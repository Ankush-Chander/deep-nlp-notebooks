{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7555dc5f-32f8-4acf-8999-8ea1dfb5939d",
   "metadata": {},
   "source": [
    "# goal: Implement sentiment classifier using transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf31c4af-4f7b-4757-8164-6f28f90fcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your pytorch convolution tools\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# load gensim google vectors\n",
    "import gensim.downloader as api\n",
    "word_vectors = api.load('word2vec-google-news-300')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f214c9cc-2476-45d4-8214-a5ec9390730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be42c4c7-2415-4ab3-a973-cb9bec9c22d5",
   "metadata": {},
   "source": [
    "# data download\n",
    "\n",
    "Download data from [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352af132-c7b0-4fd4-9087-2aa9072854d0",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb54de4d-019a-4f63-98ad-6653095e0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# data loading\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "\n",
    "# # load gensim google vectors\n",
    "# word_vectors = api.load('word2vec-google-news-300')\n",
    "\n",
    "\n",
    "def preprocess_data(filepath):\n",
    "    \"\"\"\n",
    "    load data from file. convert labels from string to numbers\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(filepath,skiprows=0)\n",
    "    # modify  dataset[1] such that positive = 1, negative=0\n",
    "    dataset[\"sentiment\"] = dataset[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def tokenize_and_vectorize_sample(sample, max_len=400, embedding_dims=300):\n",
    "    \"\"\"\n",
    "    takes text as input and return word vectors as output\n",
    "    \"\"\"\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    tokens = tokenizer.tokenize(sample)\n",
    "    sample_vecs = []\n",
    "    zero_vector = []\n",
    "    for _ in range(embedding_dims):\n",
    "        zero_vector.append(0.0)\n",
    "    \n",
    "    for token in tokens:\n",
    "        try:\n",
    "            sample_vecs.append(word_vectors[token])\n",
    "            if len(sample_vecs)>= max_len:\n",
    "                return sample_vecs\n",
    "            # print(f\"keeping: {token}\")\n",
    "        except KeyError:\n",
    "            # print(f\"skipping: {token}\")\n",
    "            pass  # No matching token in the Google w2v vocab\n",
    "\n",
    "    additional_elems = max((max_len - len(sample_vecs)),0)\n",
    "    # print(f\"max(({max_len} - {len(sample_vecs)}),0):{additional_elems}\")\n",
    "    for _ in range(additional_elems):\n",
    "        sample_vecs.append(zero_vector)\n",
    "    return sample_vecs\n",
    "\n",
    "\n",
    "dataset = preprocess_data(\"data/IMDB_Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535fb14-9003-4d73-9043-a6cf36e695f1",
   "metadata": {},
   "source": [
    "# test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a832e5dd-d954-4b87-aaaa-bb6e5c13f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_point = int(len(dataset)*.8)\n",
    "\n",
    "x_train = [sample[0] for i, sample in dataset.iloc[1:split_point,:].iterrows()]\n",
    "y_train = [sample[1] for i, sample in dataset.iloc[1:split_point,:].iterrows()]\n",
    "\n",
    "x_test = [sample[0] for i, sample in dataset.iloc[split_point:,:].iterrows()]\n",
    "y_test = [sample[1] for i, sample in dataset.iloc[split_point:,:].iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03e63de-0989-4426-83e4-10ae5e3f5d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    }
   ],
   "source": [
    "# tokenize_and_vectorize_sample(x_train[0])\n",
    "print(len(x_train[0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6a8149-119c-4593-b125-10dabadc805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(x_train, y_train, batch_size):\n",
    "    next_x_batch, next_y_batch = [], []\n",
    "    with tqdm(total=len(x_train), position=0, leave=True) as pbar:\n",
    "        for ip, output in zip(x_train, y_train):\n",
    "            next_x_batch.append(ip)\n",
    "            next_y_batch.append(output)\n",
    "            if len(next_x_batch) == batch_size:\n",
    "                yield next_x_batch, next_y_batch\n",
    "                next_x_batch, next_y_batch = [], []\n",
    "                pbar.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550f4d2e-2c97-4096-9f51-6980ece1d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the PositionalEmbedding layer\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.positional_encoding = nn.Embedding(sequence_length, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        x = x + self.positional_encoding(positions)\n",
    "        return x\n",
    "\n",
    "# Define the TransformerEncoder layer\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, dense_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dense_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = x + attn_output\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "# Define the model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, sequence_length, embed_dim, dense_dim, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = PositionalEmbedding(sequence_length, vocab_size, embed_dim)\n",
    "        self.encoder = TransformerEncoder(embed_dim, dense_dim, num_heads)\n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(embed_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x,padding_mask=True):\n",
    "        # Apply padding mask\n",
    "        if padding_mask is not None:\n",
    "            # print(f\"before: x.shape: {x.shape}\")\n",
    "            idx = (x != 0.).all(2).all(0)\n",
    "            x = x[:, idx]\n",
    "            # print(f\"after: x.shape: {x.shape}\")\n",
    "            # x = x.masked_fill(padding_mask.unsqueeze(1).unsqueeze(2), 0.0)\n",
    "            \n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faafaa13-d537-4e0d-9cbd-d093d29092e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (embedding): PositionalEmbedding(\n",
      "    (positional_encoding): Embedding(400, 300)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
      "    )\n",
      "    (feed_forward): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=300, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (pooling): AdaptiveMaxPool1d(output_size=1)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "vocab_size = 20000\n",
    "sequence_length = 400\n",
    "embed_dim = 300\n",
    "num_heads = 2\n",
    "dense_dim = 64\n",
    "batch_size=1\n",
    "\n",
    "t_model = TransformerModel(vocab_size, sequence_length, embed_dim, dense_dim, num_heads)\n",
    "t_model = to_device(t_model, device)\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.RMSprop(t_model.parameters())\n",
    "optimizer = optim.Adam(t_model.parameters())\n",
    "\n",
    "# Print model summary (not as detailed as Keras)\n",
    "print(t_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152536ac-55b6-43d4-ab5a-b189c860a525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:32<00:00, 146.56it/s]\n",
      " 10%|█████▊                                                    | 1/10 [04:32<40:56, 272.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(0): total_loss=1223987.9144337692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:27<00:00, 149.47it/s]\n",
      " 20%|███████████▌                                              | 2/10 [09:00<35:58, 269.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(1): total_loss=2000700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:24<00:00, 151.07it/s]\n",
      " 30%|█████████████████▍                                        | 3/10 [13:25<31:12, 267.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(2): total_loss=2000700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:26<00:00, 149.99it/s]\n",
      " 40%|███████████████████████▏                                  | 4/10 [17:51<26:43, 267.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(3): total_loss=2000700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:24<00:00, 151.14it/s]\n",
      " 50%|█████████████████████████████                             | 5/10 [22:16<22:11, 266.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(4): total_loss=2000700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:22<00:00, 152.23it/s]\n",
      " 60%|██████████████████████████████████▊                       | 6/10 [26:39<17:40, 265.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(5): total_loss=2000700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:24<00:00, 151.01it/s]\n",
      " 70%|████████████████████████████████████████▌                 | 7/10 [31:04<13:15, 265.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(6): total_loss=2000700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 39999/39999 [04:24<00:00, 151.18it/s]\n",
      " 80%|██████████████████████████████████████████████▍           | 8/10 [35:28<08:49, 264.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(7): total_loss=2000700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████▏                                 | 13476/39999 [01:31<03:05, 143.37it/s]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 10\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     for data, target in int_train_ds:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = epochs  # Example value for epochs\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    t_model.train()     \n",
    "    loss_val = 0\n",
    "    for i, (x_batch, y_batch) in enumerate(generate_batch(x_train, y_train, batch_size=batch_size)):\n",
    "        # print(i)\n",
    "        x_batch = [tokenize_and_vectorize_sample(sample, max_len=sequence_length) for sample in x_batch]\n",
    "        # print(f\"len(x_batch: {len(x_batch)}\")\n",
    "        # print(f\"[len(x) for x in x_batch]: {[len(x) for x in x_batch]}\")\n",
    "        # print(f\"len(x_batch[0][0]: {len(x_batch[0][0])}\")\n",
    "        x_batch = Variable(torch.FloatTensor(x_batch))\n",
    "        x_batch = to_device(x_batch, device)\n",
    "        # x_batch = x_batch.permute(0, 2, 1)\n",
    "        # print(x_batch.shape)\n",
    "        y_batch = to_device(Variable(torch.FloatTensor([y_batch])), device)\n",
    "        y_batch = y_batch.reshape(batch_size,1)\n",
    "        outputs = t_model(x_batch)\n",
    "        # print(outputs)\n",
    "        # print(y_batch)\n",
    "        # print(f\"outputs[:5]: {outputs[:5]}\")\n",
    "        # print(f\"y_batch[:5]: {y_batch[:5]}\")\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_val += loss.item()\n",
    "        optimizer.step()\n",
    "        # if i==200:\n",
    "        #     break\n",
    "    print(f\"epoch({epoch}): total_loss={loss_val}\")\n",
    "    loss_val=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b4f3f-7345-4f81-9aff-c71a52aee48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fbc60-2dbe-4126-ab57-a988022c6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_name = f\"transformer_{vocab_size}_{sequence_length}_{embed_dim}_{dense_dim}_{num_heads}.pth\"\n",
    "torch.save(t_model.state_dict(), model_name)\n",
    "\n",
    "# Load the model\n",
    "loaded_model = TransformerModel(vocab_size, sequence_length, embed_dim, dense_dim, num_heads)\n",
    "loaded_model = to_device(loaded_model, device)\n",
    "loaded_model.load_state_dict(torch.load(model_name))\n",
    "loaded_model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9931d-9380-4a90-9cf0-0578fb7cf117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the model and prepare input data (as shown in the previous responses)\n",
    "\n",
    "def evaluate(x_test, y_test, batch_size=1):\n",
    "    print(f\"len(x_test) == len(y_test): {len(x_test)} == {len(y_test)}\")\n",
    "    predictions = []\n",
    "    batches = int(len(x_test)/batch_size) +1\n",
    "    for i in tqdm(range(batches)):\n",
    "        x_batch = x_test[i:i+batch_size]\n",
    "        y_batch = y_test[i:i+batch_size]\n",
    "        \n",
    "        if not x_batch or not y_batch:\n",
    "            break\n",
    "        \n",
    "        x_batch = [tokenize_and_vectorize_sample(sample, max_len=sequence_length) for sample in x_batch]\n",
    "        \n",
    "        x_batch = Variable(torch.FloatTensor(x_batch))\n",
    "        x_batch = to_device(x_batch, device)\n",
    "        \n",
    "        \n",
    "        y_batch = to_device(Variable(torch.FloatTensor([y_batch])), device)\n",
    "        y_batch = y_batch.reshape(batch_size,1)\n",
    "        y_batch = to_device(y_batch, device)\n",
    "        # print(x_batch.shape)\n",
    "        # Perform inference on the test data\n",
    "        with torch.no_grad():\n",
    "            # Forward pass to get predictions\n",
    "            batch_predictions = loaded_model(x_batch)\n",
    "            # print(f\"batch_predictions: {batch_predictions}\")\n",
    "            # Assuming 'predictions' is the model's predictions (binary values)\n",
    "            # print(predictions)\n",
    "            # Convert predictions to binary values based on a threshold (e.g., 0.5 for binary classification)\n",
    "            threshold = 0.5\n",
    "            binary_predictions = (batch_predictions > threshold).float()\n",
    "            binary_predictions = [bp.squeeze(0).cpu() for bp in binary_predictions]\n",
    "            # print(f\"binary_predictions.squeeze(): {binary_predictions.squeeze()}\")\n",
    "            predictions.extend(binary_predictions)\n",
    "            \n",
    "            # print(f\"len(binary_predictions):{len(binary_predictions)}\")\n",
    "    \n",
    "    total = min(len(y_test), len(predictions))\n",
    "    # print(y_test[:total])\n",
    "    # print(predictions[:total])\n",
    "    accuracy = accuracy_score(y_test[:total], predictions[:total])\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "evaluate(x_train, y_train)\n",
    "# print(type(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8392c5-98e4-4c41-bc04-490008c0f05d",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b1a71-1daa-4176-a91a-bf7fbcdc043b",
   "metadata": {},
   "source": [
    "# inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
