{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7555dc5f-32f8-4acf-8999-8ea1dfb5939d",
   "metadata": {},
   "source": [
    "# goal: Implement sentiment classifier using transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf31c4af-4f7b-4757-8164-6f28f90fcdbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T08:35:24.943678401Z",
     "start_time": "2023-10-22T08:35:24.877484782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import your pytorch convolution tools\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# load gensim google vectors\n",
    "# import gensim.downloader as api\n",
    "# word_vectors = api.load('word2vec-google-news-300')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f214c9cc-2476-45d4-8214-a5ec9390730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be42c4c7-2415-4ab3-a973-cb9bec9c22d5",
   "metadata": {},
   "source": [
    "# data download\n",
    "\n",
    "Download data from [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352af132-c7b0-4fd4-9087-2aa9072854d0",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb54de4d-019a-4f63-98ad-6653095e0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "# data loading\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "\n",
    "# # load gensim google vectors\n",
    "# word_vectors = api.load('word2vec-google-news-300')\n",
    "\n",
    "\n",
    "def preprocess_data(filepath):\n",
    "    \"\"\"\n",
    "    load data from file. convert labels from string to numbers\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(filepath, skiprows=0)\n",
    "    # modify  dataset[1] such that positive = 1, negative=0\n",
    "    dataset[\"sentiment\"] = dataset[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def clean_and_tokenize_sample(text):\n",
    "    \"\"\"\n",
    "    takes text as input and return tokens as output\n",
    "    \"\"\"\n",
    "    # clean text\n",
    "    # remove html tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "    # remove punctuations\n",
    "\n",
    "\n",
    "dataset = preprocess_data(\"data/IMDB_Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c9cfda-ce2c-4ba2-977e-294d843c7023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 50000/50000 [00:18<00:00, 2633.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# vocabulary management\n",
    "samples = [sample[0] for i, sample in dataset.iloc[::].iterrows()]\n",
    "# print(samples[0])\n",
    "word_count = defaultdict(int)\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "# loop over samples to create vocabulary of size 20000\n",
    "for sample in tqdm(samples):\n",
    "    for word in clean_and_tokenize_sample(sample):\n",
    "        word_count[word] += 1\n",
    "# sort word_count by value\n",
    "sorted_word_count = sorted(word_count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(type(sorted_word_count))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ffac050f132de1d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# create word2idx and idx2word\n",
    "word2idx['<PAD>'] = 0\n",
    "idx2word[0] = '<PAD>'\n",
    "word2idx['[UNK]'] = 1\n",
    "idx2word[1] = '[UNK]'\n",
    "\n",
    "for idx, (word, count) in enumerate(sorted_word_count[:20000], start=2):\n",
    "    word2idx[word] = idx\n",
    "    idx2word[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6cfa114-c7bd-4ba7-8a56-f7be9e89814b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T08:34:49.450095186Z",
     "start_time": "2023-10-22T08:34:49.393763548Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_sample(text, seq_length):\n",
    "    # tokenize text\n",
    "    tokens = clean_and_tokenize_sample(text)\n",
    "    token_idx = [word2idx.get(token, 1) for token in tokens]\n",
    "    padding_numbers = [0] * (seq_length - len(token_idx))\n",
    "    token_idx = token_idx + padding_numbers\n",
    "    return token_idx[:seq_length]\n",
    "\n",
    "# vectorize_sample(samples[0], seq_length=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535fb14-9003-4d73-9043-a6cf36e695f1",
   "metadata": {},
   "source": [
    "# test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a832e5dd-d954-4b87-aaaa-bb6e5c13f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_point = int(len(dataset) * .8)\n",
    "\n",
    "x_train = [sample[0] for i, sample in dataset.iloc[1:split_point, :].iterrows()]\n",
    "y_train = [sample[1] for i, sample in dataset.iloc[1:split_point, :].iterrows()]\n",
    "\n",
    "x_test = [sample[0] for i, sample in dataset.iloc[split_point:, :].iterrows()]\n",
    "y_test = [sample[1] for i, sample in dataset.iloc[split_point:, :].iterrows()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f03e63de-0989-4426-83e4-10ae5e3f5d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39999\n"
     ]
    }
   ],
   "source": [
    "# tokenize_and_vectorize_sample(x_train[0])\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf6a8149-119c-4593-b125-10dabadc805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(x_train, y_train, batch_size):\n",
    "    next_x_batch, next_y_batch = [], []\n",
    "    with tqdm(total=len(x_train), position=0, leave=True) as pbar:\n",
    "        for ip, output in zip(x_train, y_train):\n",
    "            next_x_batch.append(ip)\n",
    "            next_y_batch.append(output)\n",
    "            if len(next_x_batch) == batch_size:\n",
    "                yield next_x_batch, next_y_batch\n",
    "                next_x_batch, next_y_batch = [], []\n",
    "                pbar.update(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "550f4d2e-2c97-4096-9f51-6980ece1d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the PositionalEmbedding layer\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.positional_encoding = nn.Embedding(sequence_length, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        x = x + self.positional_encoding(positions)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the TransformerEncoder layer\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, dense_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dense_dim, dense_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = x + attn_output\n",
    "        x = self.feed_forward(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, sequence_length, embed_dim, dense_dim, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = PositionalEmbedding(sequence_length, vocab_size, embed_dim)\n",
    "        self.encoder = TransformerEncoder(embed_dim, dense_dim, num_heads)\n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(dense_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, padding_mask=True):\n",
    "        # Apply padding mask\n",
    "        # print(x)\n",
    "        if padding_mask is not None:\n",
    "            # print(f\"before: x.shape: {x.shape}\")\n",
    "            # remove 0 padded values from tensor x\n",
    "            x= x[:, x.sum(axis=0) != 0]\n",
    "            # print(f\"after: x.shape: {x.shape}\")\n",
    "            # x = x.masked_fill(padding_mask.unsqueeze(1).unsqueeze(2), 0.0)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "faafaa13-d537-4e0d-9cbd-d093d29092e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (embedding): PositionalEmbedding(\n",
      "    (embedding): Embedding(20000, 256)\n",
      "    (positional_encoding): Embedding(400, 256)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (feed_forward): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (pooling): AdaptiveMaxPool1d(output_size=1)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "vocab_size = 20000\n",
    "sequence_length = 400\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 64\n",
    "batch_size = 100\n",
    "\n",
    "t_model = TransformerModel(vocab_size, sequence_length, embed_dim, dense_dim, num_heads)\n",
    "t_model = to_device(t_model, device)\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.RMSprop(t_model.parameters())\n",
    "optimizer = optim.Adam(t_model.parameters())\n",
    "\n",
    "# Print model summary (not as detailed as Keras)\n",
    "print(t_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "152536ac-55b6-43d4-ab5a-b189c860a525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:53<00:00, 742.13it/s]\n",
      "  4%|██▎                                                        | 1/25 [00:53<21:30, 53.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(0): total_loss=251.29403686523438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:55<00:00, 715.18it/s]\n",
      "  8%|████▋                                                      | 2/25 [01:49<21:04, 54.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(1): total_loss=208.88239336013794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:56<00:00, 705.22it/s]\n",
      " 12%|███████                                                    | 3/25 [02:46<20:25, 55.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(2): total_loss=184.27316710352898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:57<00:00, 695.26it/s]\n",
      " 16%|█████████▍                                                 | 4/25 [03:43<19:43, 56.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(3): total_loss=166.67442199587822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:57<00:00, 695.51it/s]\n",
      " 20%|███████████▊                                               | 5/25 [04:40<18:54, 56.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(4): total_loss=155.39639689028263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:57<00:00, 690.40it/s]\n",
      " 24%|██████████████▏                                            | 6/25 [05:38<18:04, 57.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(5): total_loss=145.0745263695717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:57<00:00, 692.44it/s]\n",
      " 28%|████████████████▌                                          | 7/25 [06:36<17:10, 57.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(6): total_loss=134.1128852814436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:57<00:00, 692.22it/s]\n",
      " 32%|██████████████████▉                                        | 8/25 [07:33<16:15, 57.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(7): total_loss=124.08535158634186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:57<00:00, 691.55it/s]\n",
      " 36%|█████████████████████▏                                     | 9/25 [08:31<15:19, 57.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(8): total_loss=118.78488986194134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:57<00:00, 691.68it/s]\n",
      " 40%|███████████████████████▏                                  | 10/25 [09:29<14:23, 57.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(9): total_loss=108.06754359602928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [01:58<00:00, 335.66it/s]\n",
      " 44%|█████████████████████████▌                                | 11/25 [11:28<17:48, 76.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(10): total_loss=99.30397672951221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████▊| 39900/39999 [00:50<00:00, 788.42it/s]\n",
      " 48%|███████████████████████████▊                              | 12/25 [12:18<14:50, 68.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(11): total_loss=99.04220001399517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:33<00:00, 1185.63it/s]\n",
      " 52%|██████████████████████████████▏                           | 13/25 [12:52<11:35, 57.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(12): total_loss=91.42107579112053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:33<00:00, 1182.71it/s]\n",
      " 56%|████████████████████████████████▍                         | 14/25 [13:26<09:16, 50.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(13): total_loss=81.95591749250889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:33<00:00, 1181.92it/s]\n",
      " 60%|██████████████████████████████████▊                       | 15/25 [14:00<07:35, 45.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(14): total_loss=74.065638191998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:33<00:00, 1179.37it/s]\n",
      " 64%|█████████████████████████████████████                     | 16/25 [14:33<06:18, 42.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(15): total_loss=69.23877700045705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:33<00:00, 1176.15it/s]\n",
      " 68%|███████████████████████████████████████▍                  | 17/25 [15:07<05:16, 39.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(16): total_loss=68.51140880957246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1168.02it/s]\n",
      " 72%|█████████████████████████████████████████▊                | 18/25 [15:41<04:25, 37.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(17): total_loss=66.5126073770225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1172.53it/s]\n",
      " 76%|████████████████████████████████████████████              | 19/25 [16:15<03:40, 36.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(18): total_loss=61.380131382495165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1172.02it/s]\n",
      " 80%|██████████████████████████████████████████████▍           | 20/25 [16:50<02:59, 35.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(19): total_loss=59.749193392693996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1166.24it/s]\n",
      " 84%|████████████████████████████████████████████████▋         | 21/25 [17:24<02:21, 35.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(20): total_loss=58.772314205765724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1161.81it/s]\n",
      " 88%|███████████████████████████████████████████████████       | 22/25 [17:58<01:45, 35.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(21): total_loss=53.74704580195248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1161.34it/s]\n",
      " 92%|█████████████████████████████████████████████████████▎    | 23/25 [18:32<01:09, 34.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(22): total_loss=52.435563907027245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1156.44it/s]\n",
      " 96%|███████████████████████████████████████████████████████▋  | 24/25 [19:07<00:34, 34.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(23): total_loss=58.75098267570138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████▉| 39900/39999 [00:34<00:00, 1156.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 25/25 [19:41<00:00, 47.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch(24): total_loss=50.378406984731555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 25\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     for data, target in int_train_ds:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = epochs  # Example value for epochs\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    t_model.train()\n",
    "    loss_val = 0\n",
    "    for i, (x_batch, y_batch) in enumerate(generate_batch(x_train, y_train, batch_size=batch_size)):\n",
    "        # print(i)\n",
    "        x_batch = [vectorize_sample(sample, seq_length=sequence_length) for sample in x_batch]\n",
    "        # print(f\"len(x_batch: {len(x_batch)}\")\n",
    "        # print(f\"[len(x) for x in x_batch]: {[len(x) for x in x_batch]}\")\n",
    "        # print(f\"len(x_batch[0][0]: {len(x_batch[0][0])}\")\n",
    "        x_batch = Variable(torch.LongTensor(x_batch))\n",
    "        x_batch = to_device(x_batch, device)\n",
    "        # x_batch = x_batch.permute(0, 2, 1)\n",
    "        # print(x_batch.shape)\n",
    "        y_batch = to_device(Variable(torch.FloatTensor([y_batch])), device)\n",
    "        y_batch = y_batch.reshape(batch_size, 1)\n",
    "        outputs = t_model(x_batch)\n",
    "        # print(outputs)\n",
    "        # print(y_batch)\n",
    "        # print(f\"outputs[:5]: {outputs[:5]}\")\n",
    "        # print(f\"y_batch[:5]: {y_batch[:5]}\")\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        loss_val += loss.item()\n",
    "        optimizer.step()\n",
    "        # if i==200:\n",
    "        #     break\n",
    "    print(f\"epoch({epoch}): total_loss={loss_val}\")\n",
    "    loss_val = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "073fbc60-2dbe-4126-ab57-a988022c6364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_name = f\"transformer_{vocab_size}_{sequence_length}_{embed_dim}_{dense_dim}_{num_heads}.pth\"\n",
    "torch.save(t_model.state_dict(), model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0e1e925-0cd1-40ca-80c6-a9d7309df07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): PositionalEmbedding(\n",
       "    (embedding): Embedding(20000, 256)\n",
       "    (positional_encoding): Embedding(400, 256)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pooling): AdaptiveMaxPool1d(output_size=1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model_name = f\"transformer_{vocab_size}_{sequence_length}_{embed_dim}_{dense_dim}_{num_heads}.pth\"\n",
    "loaded_model = TransformerModel(vocab_size, sequence_length, embed_dim, dense_dim, num_heads)\n",
    "loaded_model = to_device(loaded_model, device)\n",
    "loaded_model.load_state_dict(torch.load(model_name))\n",
    "loaded_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "67c9931d-9380-4a90-9cf0-0578fb7cf117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(x_test) == len(y_test): 100 == 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                  | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_predictions: tensor([[0.0505]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1124]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1421]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.5070]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1407]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2843]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.5601]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2724]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0071]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1412]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0731]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2521]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1214]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0571]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0105]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2335]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0139]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0680]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0461]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.4491]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0884]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.6195]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0348]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1558]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1501]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0321]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0317]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2740]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.6142]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1007]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1531]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0140]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1496]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1329]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████                                   | 38/101 [00:00<00:00, 379.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_predictions: tensor([[0.0090]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.3203]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0616]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2738]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0689]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0510]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0119]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0822]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1129]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0128]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1963]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1965]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0694]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0975]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0102]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0261]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.6683]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0019]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0315]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.7231]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0539]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2216]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.4418]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2004]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.4136]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0138]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2255]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.8998]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0054]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0771]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0157]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0070]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.3083]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1391]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0681]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.8530]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0268]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1556]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.8853]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2732]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.5103]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0120]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0311]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████████████████████████████████████████▏            | 78/101 [00:00<00:00, 388.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_predictions: tensor([[0.0712]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████▍| 100/101 [00:00<00:00, 387.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_predictions: tensor([[0.5114]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1105]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0154]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.7924]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1584]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0186]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1243]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0027]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2192]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.8620]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0695]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0456]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0346]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0198]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0594]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.8122]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0459]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0576]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.1262]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.2614]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0005]], device='cuda:0')\n",
      "batch_predictions: tensor([[0.0129]], device='cuda:0')\n",
      "Accuracy: 0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load the model and prepare input data (as shown in the previous responses)\n",
    "\n",
    "def evaluate(x_test, y_test, batch_size=1):\n",
    "    print(f\"len(x_test) == len(y_test): {len(x_test)} == {len(y_test)}\")\n",
    "    predictions = []\n",
    "    \n",
    "    batches = int(len(x_test) / batch_size) + 1\n",
    "    for i in tqdm(range(batches)):\n",
    "        x_batch = x_test[i:i + batch_size]\n",
    "        y_batch = y_test[i:i + batch_size]\n",
    "\n",
    "        if not x_batch or not y_batch:\n",
    "            break\n",
    "\n",
    "        x_batch = [vectorize_sample(sample, seq_length=sequence_length) for sample in x_batch]\n",
    "\n",
    "        x_batch = Variable(torch.LongTensor(x_batch))\n",
    "        x_batch = to_device(x_batch, device)\n",
    "\n",
    "        y_batch = to_device(Variable(torch.FloatTensor([y_batch])), device)\n",
    "        y_batch = y_batch.reshape(batch_size, 1)\n",
    "        y_batch = to_device(y_batch, device)\n",
    "        # print(x_batch.shape)\n",
    "        # Perform inference on the test data\n",
    "        with torch.no_grad():\n",
    "            # Forward pass to get predictions\n",
    "            batch_predictions = loaded_model(x_batch)\n",
    "            # Assuming 'predictions' is the model's predictions (binary values)\n",
    "            # print(predictions)\n",
    "            # Convert predictions to binary values based on a threshold (e.g., 0.5 for binary classification)\n",
    "            print(f\"batch_predictions: {batch_predictions}\")\n",
    "            \n",
    "            threshold = 0.5\n",
    "            binary_predictions = (batch_predictions > threshold).float()\n",
    "            \n",
    "            # print(f\"binary_predictions: {binary_predictions}\")\n",
    "            binary_predictions = [bp.squeeze(0).cpu() for bp in binary_predictions]\n",
    "            # print(f\"binary_predictions: {binary_predictions}\")\n",
    "            predictions.extend(binary_predictions)\n",
    "\n",
    "            # print(f\"len(binary_predictions):{len(binary_predictions)}\")\n",
    "\n",
    "    total = min(len(y_test), len(predictions))\n",
    "    # print(y_test[:total])\n",
    "    # print(predictions[:total])\n",
    "    accuracy = accuracy_score(y_test[:total], predictions[:total])\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# evaluate(x_test, y_test)\n",
    "x_positive_train = [x for i,x in enumerate(x_train) if y_train[i]==1]\n",
    "y_positive_train = [y for y in y_train if y==1]\n",
    "\n",
    "x_positive_test = [x for i,x in enumerate(x_test) if y_train[i]==1]\n",
    "y_positive_test = [y for y in y_test if y==1]\n",
    "# evaluate(x_train, y_train)\n",
    "evaluate(x_positive_test[:100], y_positive_test[:100])\n",
    "# print(len([y for y in y_test if y==1]))\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8392c5-98e4-4c41-bc04-490008c0f05d",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ddbf0baf-bf86-4c8d-84ef-09829af202c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad9727-3333-4ab9-b85a-ed7041349e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69808d65-f55f-4e1d-b1a1-bace97ab3cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2e7b9-2df2-4b1b-966a-09af4a4af5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bfeb9b-b3c3-4351-a9e9-a87f449d3bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aee86a-e8c6-4c79-8fb5-1d48e3bec134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7f8ee-bdc2-4c66-bae4-be9226a9e2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b0ded-752b-4f1c-be55-339dfcd9ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93d4d8-b753-414d-954d-5d34b303281d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635d1e3-4974-4051-a0b9-b141fc26b0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202328e-6c8f-40c7-a938-8cb77f7da585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f033a3-e75e-4034-a6e7-4765b0d29d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c010c-a980-4bff-9611-45f6185f24d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d07801-db0e-4cb4-92f3-fadd9e4baeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67f723-c0c0-4bd6-a0da-7da6113048e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b208367-7eeb-4077-9e48-4bc227a896d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "89d7851c-7d8f-487d-ab29-b207e965c29a",
   "metadata": {},
   "source": [
    "/}////////]///.';;;;;;;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
