{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tryout pretrained word2vec model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "111cddeae802245f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:12.969895651Z",
     "start_time": "2023-08-23T04:55:44.379734376Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "# inspect vocabulary\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:13.012019659Z",
     "start_time": "2023-08-23T04:56:13.010862128Z"
    }
   },
   "id": "8066856232b6f114"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car|minivan|0.6907036900520325\n",
      "car|bicycle|0.5364484190940857\n",
      "car|airplane|0.42435577511787415\n",
      "car|cereal|0.13924746215343475\n",
      "car|communism|0.05820293352007866\n"
     ]
    }
   ],
   "source": [
    "# check pairwise similarity\n",
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print(f\"{w1}|{w2}|{wv.similarity(w1, w2)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:13.012560063Z",
     "start_time": "2023-08-23T04:56:13.011327445Z"
    }
   },
   "id": "2315bfc749d28af1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827)]\n",
      "[('Sounders', 0.627106249332428), ('Sounders_FC', 0.6018840670585632)]\n",
      "[('Mozart', 0.5742169618606567), ('Beethoven', 0.5615471601486206)]\n"
     ]
    }
   ],
   "source": [
    "# answer analogy questions\n",
    "# king + woman - man = ?\n",
    "# man:woman::king:?\n",
    "print(wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=2))\n",
    "\n",
    "# wv['Timbers'] - wv['Portland'] + wv['Seattle'] = ?\n",
    "print(wv.most_similar(positive=['Timbers', 'Seattle'], negative=['Portland'], topn=2))\n",
    "\n",
    "# wv['Einstein'] - wv['physics'] + wv['classical_music'] = ?\n",
    "print(wv.most_similar(positive=['Einstein', 'classical_music'], negative=['physics'], topn=2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:15.036504656Z",
     "start_time": "2023-08-23T04:56:13.011526237Z"
    }
   },
   "id": "98f316ff7b7719ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train your own word2vec model: using gensim "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ac5d439510ae1fe"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# prepare sentence corpus from jsonl file\n",
    "import os\n",
    "import ujson\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def convert_sentences_from_jsonl_file(filepath:str):\n",
    "    output_path = \"data/mahabharat_gutenberg_lemmatized_sents.txt\"\n",
    "    if os.path.exists(output_path):\n",
    "        return\n",
    "    \n",
    "    with open(output_path, \"w+\") as fp_write:\n",
    "        with open(filepath) as fp_r:\n",
    "            for line in fp_r.readlines():\n",
    "                section = ujson.loads(line)\n",
    "                paragraphs = section[\"paragraphs\"]\n",
    "                paragraph_docs = nlp.pipe(paragraphs)\n",
    "                for p_doc in paragraph_docs:\n",
    "                    for sent in p_doc.sents:\n",
    "                        if len(sent) > 4:\n",
    "                            sent_lemma = \" \".join([token.lemma_ for token in sent if not token.is_stop and not token.is_punct])                   \n",
    "                            fp_write.write(f\"{sent_lemma}\\n\")\n",
    "\n",
    "convert_sentences_from_jsonl_file(\"data/mahabharat_gutenberg.jsonl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:15.876819647Z",
     "start_time": "2023-08-23T04:56:15.033890254Z"
    }
   },
   "id": "42a15c36093bdc8e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import re\n",
    "al_regex = re.compile(r\"[^a-zA-Z]\")\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = \"data/mahabharat_gutenberg_lemmatized_sents.txt\"\n",
    "        with open(corpus_path) as fp:\n",
    "            for line in fp.readlines():\n",
    "                tokens = line.split()\n",
    "                tokens = [al_regex.sub('', token) for token in tokens]\n",
    "                yield tokens\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:15.883113110Z",
     "start_time": "2023-08-23T04:56:15.878959154Z"
    }
   },
   "id": "da3d40204842945f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 10.462077617645264 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "s_time = time.time()\n",
    "mahabharat_model = gensim.models.Word2Vec(sentences=sentences)\n",
    "print(f\"Time taken to train word2vec model: {time.time() - s_time} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:26.346083643Z",
     "start_time": "2023-08-23T04:56:15.882239468Z"
    }
   },
   "id": "d1fd9d84d7816d33"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/16456 is o\n",
      "word #1/16456 is thou\n",
      "word #2/16456 is say\n",
      "word #3/16456 is king\n",
      "word #4/16456 is great\n",
      "word #5/16456 is man\n",
      "word #6/16456 is thee\n",
      "word #7/16456 is son\n",
      "word #8/16456 is art\n",
      "word #9/16456 is thy\n"
     ]
    }
   ],
   "source": [
    "my_wv = mahabharat_model.wv\n",
    "for index, word in enumerate(my_wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(my_wv.index_to_key)} is {word}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:26.353201499Z",
     "start_time": "2023-08-23T04:56:26.347388718Z"
    }
   },
   "id": "f499a33a687bfcbb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krishna: ['Vasudeva', 'Govinda', 'Kesava', 'Hrishikesa', 'Dhananjaya', 'Madhava', 'Mahadeva', 'Hari', 'Panchala', 'Janardana']\n",
      "mace: ['club', 'lance', 'discus', 'spiked', 'sword', 'axis', 'spear', 'uplifted', 'scimitar', 'combatant']\n",
      "Bhishma: ['Vaisampayana', 'Kanika', 'Sauti', 'sringa', 'XI', 'Vamadeva', 'reharnesse', 'religiously', 'Volume', 'Vyasa']\n",
      "Drona: ['pupil', 'Karna', 'Aswatthaman', 'Kripa', 'Salya', 'Bharadwaja', 'Phalguna', 'Arjuna', 'Dussasana', 'Duryodhana']\n",
      "Pandu: ['Kunti', 'Pritha', 'Vikartana', 'Santanu', 'Suta', 'Haryyaswa', 'Asamanjas', 'Devayuga', 'Anadhristi', 'Madri']\n"
     ]
    }
   ],
   "source": [
    "# find similar words \n",
    "for word in [\"Krishna\", \"mace\", \"Bhishma\", \"Drona\", \"Pandu\"]:\n",
    "    top_similars = [words for words, _ in my_wv.most_similar(word, topn=10)]\n",
    "    print(f\"{word}: {top_similars}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:26.364510376Z",
     "start_time": "2023-08-23T04:56:26.350438246Z"
    }
   },
   "id": "c9d408a67c4106c8"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bhimasena', 0.5622424483299255), ('Karna', 0.5439724326133728)]\n",
      "[('Karna', 0.6152733564376831), ('Gandiva', 0.5495764017105103)]\n"
     ]
    }
   ],
   "source": [
    "# wv['Arjuna'] - wv['Krishna'] + wv['Duryodhana'] = ?\n",
    "print(my_wv.most_similar(positive=['Arjuna', 'Duryodhana'], negative=['Krishna'], topn=2))\n",
    "\n",
    "# wv['Drona'] - wv['Arjuna'] + wv['Drupada'] = ?\n",
    "print(my_wv.most_similar(positive=['Drona', 'Arjuna'], negative=['Drupada'], topn=2))\n",
    "\n",
    "# note: due to small size of corpus, analogies won\"t be as good as googlenews model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T05:12:15.069327176Z",
     "start_time": "2023-08-23T05:12:15.059314503Z"
    }
   },
   "id": "d6b31dac2e4b9fa1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train word2wec model from scratch "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc06ea8b9966bb62"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "92a6e6ce640f8c87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "1. [Paper: Efficient Estimation of Word Representations in\n",
    "Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "2. [The Illustrated Word2vec by Jay Alammar](https://jalammar.github.io/illustrated-word2vec/)\n",
    "3. [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "4. [Tensorflow-word2vec tutorial](https://www.tensorflow.org/text/tutorials/word2vec)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18829c666ee4a096"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
