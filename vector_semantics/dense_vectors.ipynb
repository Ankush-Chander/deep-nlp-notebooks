{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111cddeae802245f",
   "metadata": {},
   "source": [
    "# Tryout pretrained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:12.969895651Z",
     "start_time": "2023-08-23T04:55:44.379734376Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8066856232b6f114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:13.012019659Z",
     "start_time": "2023-08-23T04:56:13.010862128Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "# inspect vocabulary\n",
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2315bfc749d28af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:13.012560063Z",
     "start_time": "2023-08-23T04:56:13.011327445Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car|minivan|0.6907036900520325\n",
      "car|bicycle|0.5364484190940857\n",
      "car|airplane|0.42435577511787415\n",
      "car|cereal|0.13924746215343475\n",
      "car|communism|0.05820293352007866\n"
     ]
    }
   ],
   "source": [
    "# check pairwise similarity\n",
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print(f\"{w1}|{w2}|{wv.similarity(w1, w2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f316ff7b7719ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:15.036504656Z",
     "start_time": "2023-08-23T04:56:13.011526237Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827)]\n",
      "[('Sounders', 0.627106249332428), ('Sounders_FC', 0.6018840670585632)]\n",
      "[('Mozart', 0.5742169618606567), ('Beethoven', 0.5615471601486206)]\n"
     ]
    }
   ],
   "source": [
    "# answer analogy questions\n",
    "# king + woman - man = ?\n",
    "# man:woman::king:?\n",
    "print(wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=2))\n",
    "\n",
    "# wv['Timbers'] - wv['Portland'] + wv['Seattle'] = ?\n",
    "print(wv.most_similar(positive=['Timbers', 'Seattle'], negative=['Portland'], topn=2))\n",
    "\n",
    "# wv['Einstein'] - wv['physics'] + wv['classical_music'] = ?\n",
    "print(wv.most_similar(positive=['Einstein', 'classical_music'], negative=['physics'], topn=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5d439510ae1fe",
   "metadata": {},
   "source": [
    "# Train your own word2vec model: using gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a15c36093bdc8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:15.876819647Z",
     "start_time": "2023-08-23T04:56:15.033890254Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# prepare sentence corpus from jsonl file\n",
    "import os\n",
    "import ujson\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def convert_sentences_from_jsonl_file(filepath:str):\n",
    "    output_path = \"data/mahabharat_gutenberg_lemmatized_sents.txt\"\n",
    "    if os.path.exists(output_path):\n",
    "        return\n",
    "    \n",
    "    with open(output_path, \"w+\") as fp_write:\n",
    "        with open(filepath) as fp_r:\n",
    "            for line in fp_r.readlines():\n",
    "                section = ujson.loads(line)\n",
    "                paragraphs = section[\"paragraphs\"]\n",
    "                paragraph_docs = nlp.pipe(paragraphs)\n",
    "                for p_doc in paragraph_docs:\n",
    "                    for sent in p_doc.sents:\n",
    "                        if len(sent) > 4:\n",
    "                            sent_lemma = \" \".join([token.lemma_ for token in sent if not token.is_stop and not token.is_punct])                   \n",
    "                            fp_write.write(f\"{sent_lemma}\\n\")\n",
    "\n",
    "convert_sentences_from_jsonl_file(\"data/mahabharat_gutenberg.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3d40204842945f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:15.883113110Z",
     "start_time": "2023-08-23T04:56:15.878959154Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "al_regex = re.compile(r\"[^a-zA-Z]\")\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = \"data/mahabharat_gutenberg_lemmatized_sents.txt\"\n",
    "        with open(corpus_path) as fp:\n",
    "            for line in fp.readlines():\n",
    "                tokens = line.split()\n",
    "                tokens = [al_regex.sub('', token) for token in tokens]\n",
    "                yield tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fd9d84d7816d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:26.346083643Z",
     "start_time": "2023-08-23T04:56:15.882239468Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 9.266835451126099 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "s_time = time.time()\n",
    "# gensim word2vec defaults \n",
    "# self, sentences=None, corpus_file=None, vector_size=100, alpha=0.025, window=5, min_count=5,\n",
    "# max_vocab_size=None, sample=1e-3, seed=1, workers=3, min_alpha=0.0001,\n",
    "# sg=0, hs=0, negative=5, ns_exponent=0.75, cbow_mean=1, hashfxn=hash, epochs=5, null_word=0,\n",
    "# trim_rule=None, sorted_vocab=1, batch_words=MAX_WORDS_IN_BATCH, compute_loss=False, callbacks=(),\n",
    "# comment=None, max_final_vocab=None, shrink_windows=True,\n",
    "mahabharat_model = gensim.models.Word2Vec(sentences=sentences, vector_size=100, alpha=0.025, window=5, epochs=5)\n",
    "print(f\"Time taken to train word2vec model: {time.time() - s_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f499a33a687bfcbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:26.353201499Z",
     "start_time": "2023-08-23T04:56:26.347388718Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/16456 is o\n",
      "word #1/16456 is thou\n",
      "word #2/16456 is say\n",
      "word #3/16456 is king\n",
      "word #4/16456 is great\n",
      "word #5/16456 is man\n",
      "word #6/16456 is thee\n",
      "word #7/16456 is son\n",
      "word #8/16456 is art\n",
      "word #9/16456 is thy\n"
     ]
    }
   ],
   "source": [
    "my_wv = mahabharat_model.wv\n",
    "for index, word in enumerate(my_wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(my_wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d408a67c4106c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T04:56:26.364510376Z",
     "start_time": "2023-08-23T04:56:26.350438246Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krishna: ['Vasudeva', 'Govinda', 'Kesava', 'Hrishikesa', 'Dhananjaya', 'Panchala', 'Janardana', 'exalt', 'Mahadeva', 'Yudhishthira']\n",
      "mace: ['lance', 'discus', 'spiked', 'club', 'sword', 'axis', 'spear', 'dart', 'spike', 'uplifted']\n",
      "Bhishma: ['Vaisampayana', 'sringa', 'Kanika', 'XI', 'religiously', 'Sauti', 'reharnesse', 'Upamanyu', 'Volume', 'Vamadeva']\n",
      "Drona: ['Karna', 'pupil', 'Kripa', 'Aswatthaman', 'Bharadwaja', 'Phalguna', 'Salya', 'Arjuna', 'Vikarna', 'Vibhatsu']\n",
      "Pandu: ['Kunti', 'Pritha', 'Vikartana', 'Anukampaka', 'Santanu', 'Vishwamitra', 'Anadhristi', 'Saradwat', 'Bidula', 'Radha']\n"
     ]
    }
   ],
   "source": [
    "# find similar words \n",
    "for word in [\"Krishna\", \"mace\", \"Bhishma\", \"Drona\", \"Pandu\"]:\n",
    "    top_similars = [words for words, _ in my_wv.most_similar(word, topn=10)]\n",
    "    print(f\"{word}: {top_similars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6b31dac2e4b9fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T05:12:15.069327176Z",
     "start_time": "2023-08-23T05:12:15.059314503Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bhimasena', 0.5622424483299255), ('Karna', 0.5439724326133728)]\n",
      "[('Karna', 0.6152733564376831), ('Gandiva', 0.5495764017105103)]\n"
     ]
    }
   ],
   "source": [
    "# wv['Arjuna'] - wv['Krishna'] + wv['Duryodhana'] = ?\n",
    "print(my_wv.most_similar(positive=['Arjuna', 'Duryodhana'], negative=['Krishna'], topn=2))\n",
    "\n",
    "# wv['Drona'] - wv['Arjuna'] + wv['Drupada'] = ?\n",
    "print(my_wv.most_similar(positive=['Drona', 'Arjuna'], negative=['Drupada'], topn=2))\n",
    "\n",
    "# note: due to small size of corpus, analogies won\"t be as good as googlenews model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc06ea8b9966bb62",
   "metadata": {},
   "source": [
    "# Train word2wec model from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6e6ce640f8c87",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18829c666ee4a096",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [Paper: Efficient Estimation of Word Representations in\n",
    "Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "2. [The Illustrated Word2vec by Jay Alammar](https://jalammar.github.io/illustrated-word2vec/)\n",
    "3. [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)\n",
    "4. [Tensorflow-word2vec tutorial](https://www.tensorflow.org/text/tutorials/word2vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
